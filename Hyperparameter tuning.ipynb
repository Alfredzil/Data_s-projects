{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# Compare multiple Classifiers and tune the hyperparameters \n",
    "# using GridSearchCV\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Read dataset\n",
    "data = pd.read_csv('hpt_small.csv')\n",
    "\n",
    "# Create Dummy variables\n",
    "data_prep = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Create X and Y Variables\n",
    "X = data_prep.iloc[:, :-1]\n",
    "Y = data_prep.iloc[:, -1]\n",
    "\n",
    "# Import and create Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1234)\n",
    "\n",
    "# Import and create Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=1234)\n",
    "\n",
    "# Import and create Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lrc = LogisticRegression(random_state=1234)\n",
    "\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameters for Random Forest Nb : it is a dictionary\n",
    "rfc_param = {'n_estimators':[10,15,20], \n",
    "            'min_samples_split':[8,16],\n",
    "            'min_samples_leaf':[1,2,3,4,5]\n",
    "            }\n",
    "\n",
    "# The parameters results in 3 x 2 x 5 = 30 different combinations\n",
    "# CV=10 for 30 different combinations mean 300 jobs/model runs\n",
    "\n",
    "rfc_grid = GridSearchCV(estimator=rfc, \n",
    "                        param_grid=rfc_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "# Fit the data to do Grid Search\n",
    "rfc_grid_fit = rfc_grid.fit(X, Y)\n",
    "\n",
    "# Get the results of the GridSearchCV\n",
    "cv_results_rfc = pd.DataFrame.from_dict(rfc_grid_fit.cv_results_)\n",
    "\n",
    "\n",
    "\n",
    "# Define parameters for Logistic Regression\n",
    "lrc_param = {'C':[0.01, 0.1, 0.5, 1, 2, 5, 10], \n",
    "            'penalty':['l2'],\n",
    "            'solver':['liblinear','lbfgs', 'saga']\n",
    "            }\n",
    "\n",
    "# The parameters results in 7 x 1 x 3 = 21 different combinations\n",
    "# CV=10 for 21 different combinations mean 210 jobs/model runs\n",
    "\n",
    "lrc_grid = GridSearchCV(estimator=lrc, \n",
    "                        param_grid=lrc_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True,\n",
    "                        verbose=True)\n",
    "\n",
    "# Fit the data to do Grid Search using Logistic Regression\n",
    "lrc_grid_fit = lrc_grid.fit(X, Y)\n",
    "\n",
    "# Get the Grid Search results for Logistic Regression\n",
    "cv_results_lrc = pd.DataFrame.from_dict(lrc_grid_fit.cv_results_)\n",
    "\n",
    "\n",
    "# define parameters for Support Vector Classifier\n",
    "svc_param = {'C':[0.01, 0.1, 0.5, 1, 2, 5, 10], # C is the inverse of the regularisation strength\n",
    "            'kernel':['rbf', 'linear'],\n",
    "            'gamma':[0.1, 0.25, 0.5, 1, 5]\n",
    "            }\n",
    "\n",
    "# The parameters results in 7 x 2 x 5 = 70 different combinations\n",
    "# CV=10 for 70 different combinations mean 700 jobs/model runs\n",
    "\n",
    "svc_grid = GridSearchCV(estimator=svc, \n",
    "                        param_grid=svc_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "# Fit the data to do Grid Search for Support Vector\n",
    "svc_grid_fit = svc_grid.fit(X, Y)\n",
    "\n",
    "# Get the Grid Search results for Support Vector\n",
    "cv_results_svc = pd.DataFrame.from_dict(svc_grid_fit.cv_results_)\n",
    "\n",
    "# Get the top ranked test score for all the three classifiers\n",
    "rfc_top_rank = cv_results_rfc[cv_results_rfc['rank_test_score'] == 1].iloc[0]\n",
    "lrc_top_rank = cv_results_lrc[cv_results_lrc['rank_test_score'] == 1].iloc[0]\n",
    "svc_top_rank = cv_results_svc[cv_results_svc['rank_test_score'] == 1].iloc[0]\n",
    "\n",
    "\n",
    "# Print the train and test score for three classifiers\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print ('                    ',\n",
    "       '  Random Forest    ',\n",
    "       '  Logistic Regression  ',\n",
    "       '  Support Vector   ')\n",
    "\n",
    "print ('                    ',\n",
    "       '  ---------------- ',\n",
    "       '  -------------------- ',\n",
    "       '  ---------------- ')\n",
    "\n",
    "\n",
    "print ('  Mean Test Score   : ', \n",
    "       str('%.4f' %rfc_top_rank['mean_test_score']),\n",
    "       '            ',\n",
    "       str('%.4f' %lrc_top_rank['mean_test_score']),\n",
    "       '                ',\n",
    "       str('%.4f' %svc_top_rank['mean_test_score'])\n",
    "       )\n",
    "\n",
    "print ('  Mean Train Score  : ', \n",
    "       str('%.4f' %rfc_top_rank['mean_train_score']),\n",
    "       '            ',\n",
    "       str('%.4f' %lrc_top_rank['mean_train_score']),\n",
    "       '                ',\n",
    "       str('%.4f' %svc_top_rank['mean_train_score'])\n",
    "       )\n",
    "\n",
    "# Print the best parameters of the Random Forest Classifier\n",
    "print('\\n The best Parameters are : ')\n",
    "print(rfc_grid_fit.best_params_)\n",
    "\n",
    "# Randomized Search\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# Perform RandomizedSearchCV for hyperparameter tuning\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Read dataset\n",
    "data = pd.read_csv('hpt_small.csv')\n",
    "\n",
    "# Create Dummy variables\n",
    "data_prep = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Create X and Y Variables\n",
    "X = data_prep.iloc[:, :-1]\n",
    "Y = data_prep.iloc[:, -1]\n",
    "\n",
    "# Import and create Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1234)\n",
    "\n",
    "# Import RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define parameters for Random Forest\n",
    "rfc_param = {'n_estimators':[10,15,20], \n",
    "            'min_samples_split':[8,16],\n",
    "            'min_samples_leaf':[1,2,3,4,5]\n",
    "            }\n",
    "\n",
    "# The parameters results in 3 x 2 x 5 = 30 different combinations\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "rfc_rs = RandomizedSearchCV(estimator=rfc, \n",
    "                        param_distributions=rfc_param,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_iter=10,\n",
    "                        return_train_score=True,\n",
    "                        random_state=1234)\n",
    "\n",
    "# n_iter selects 10 combinations out of 30 possible\n",
    "# Now 10 x 10 = 100 jobs will be executed\n",
    "\n",
    "# Fit the data to RandomizedSearchCV object\n",
    "rfc_rs_fit = rfc_rs.fit(X, Y)\n",
    "\n",
    "# Get the results of RandomizedSearch\n",
    "cv_results_rfc_rs = pd.DataFrame.from_dict(rfc_rs_fit.cv_results_)\n",
    "\n",
    "# Print the best parameters of Randomized Search for Random Forest\n",
    "print('\\n The best Parameters are : ')\n",
    "print(rfc_rs_fit.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
